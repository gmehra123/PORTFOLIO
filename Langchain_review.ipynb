{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ee4113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb4a9836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_path = find_dotenv(filename=\"password.env\", usecwd=True)\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a10e9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322c600",
   "metadata": {},
   "source": [
    "### Simple workflow to prompt llm.\n",
    ">This uses the llm.invoke method which is more general than client.chat,completions.create that we use with open ai. The open ai method is specific to open ai, while the llm.invoke can work with all model providers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2032bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI( model=\"gpt-4o-mini\",\n",
    "                 temperature = 0,\n",
    "                 openai_api_key=key\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc4e9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='- **Problem-Solving Skills**: Math enhances critical thinking and analytical skills, enabling individuals to approach and solve complex problems in various fields, from science and engineering to finance and everyday life.\\n\\n- **Real-World Applications**: Math is essential in numerous practical applications, such as budgeting, cooking, construction, and technology, helping people make informed decisions and optimize resources.\\n\\n- **Foundation for Advanced Learning**: A strong understanding of math is crucial for pursuing advanced studies in disciplines like physics, computer science, economics, and medicine, as it provides the necessary tools for understanding and modeling real-world phenomena.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 121, 'prompt_tokens': 19, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CeMjKIvjyOh2NL4K3Q1aEDUKk6pxn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e3b8fe70-f800-4907-8a8a-609c39a30703-0', usage_metadata={'input_tokens': 19, 'output_tokens': 121, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Why is math useful? Give me 3 bullet points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ce55f",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "* Typically used for \n",
    "    * Examples (few shot prompts)\n",
    "    * Adittional context\n",
    "    * Structured questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92c9ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Explain the concept of data science in simple terms using 3 bullet points'\n"
     ]
    }
   ],
   "source": [
    "# creating a template to explain concepts\n",
    "from langchain_core.prompts import PromptTemplate\n",
    " \n",
    "template = \"Explain the concept of {concept} in simple terms using 3 bullet points\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt = prompt_template.invoke({\"concept\": \"data science\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fb7d5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='- **Learning from Data**: Machine learning is a way for computers to learn patterns and make decisions based on data, rather than being explicitly programmed for every task.\\n\\n- **Improvement Over Time**: As more data is fed into the system, the machine learning model can improve its accuracy and performance, adapting to new information and changing conditions.\\n\\n- **Applications Everywhere**: Machine learning is used in various everyday applications, such as recommending movies, recognizing speech, and detecting spam emails, making technology smarter and more user-friendly.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 105, 'prompt_tokens': 21, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CeN0vb2o9jchT3zrfRfjaKNkXbxAh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--b2224cda-e7b6-47fc-baa7-bbbb1a21975d-0' usage_metadata={'input_tokens': 21, 'output_tokens': 105, 'total_tokens': 126, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# full workflow with LLM and prompt template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Write the template string and create a PromptTemplate object\n",
    "template = \"Explain the following concept concisely in 3 bullet points: {concept}\"\n",
    "template = PromptTemplate.from_template(template)\n",
    "\n",
    "#create an appropriate llm\n",
    "llm = ChatOpenAI( model=\"gpt-4o-mini\",\n",
    "                 temperature = 0,\n",
    "                 openai_api_key=key\n",
    "                 )\n",
    "# Define the llm chain\n",
    "llm_chain = (prompt_template) | (llm)\n",
    "concept = \"machine learning\"\n",
    "response = llm_chain.invoke({\"concept\": concept})\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735ec58",
   "metadata": {},
   "source": [
    "### ChatPrompt template\n",
    "> This kind of prompt template allows us to use Chat roles in the template. We can use roles to pass example conversations and system messages along with every prompt that is created with this template. This helps structure reponses in the correct format (using example conversations).\n",
    "\n",
    ">The template is structured as a list of tuples. Each tuple has a role and the associtaed prompt with the role. The last tuple is typically the prompt where the user is asking the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7924365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "dt_def = \"\"\"A decision tree is a supervised learning algorithm that uses a tree-like structure \n",
    "to make predictions or classifications based on a series of questions about a dataset. \n",
    "It starts with a root node, branches out through internal nodes (which represent tests on features), \n",
    "and ends at leaf nodes (which are the final decisions or outcomes). Decision trees can be used for both regression and classification tasks \n",
    "and are known for being easy to interpret, as they mimic a flowchart of human decision-making. \"\"\"\n",
    "\n",
    "# Define the template\n",
    "template = [\n",
    "    (\"system\",\"You are a helpful datascience explainer\"),\n",
    "    (\"human\",\"answer this question: what is a descion tree?\"),\n",
    "    (\"ai\",dt_def),\n",
    "    (\"human\", \"answer this question:{dt_question}\")\n",
    "\n",
    "    ]\n",
    "llm = ChatOpenAI( model=\"gpt-4o-mini\",\n",
    "                 temperature = 0,\n",
    "                 openai_api_key=key)\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(template)\n",
    "llm_chain = (template) | (llm)\n",
    "dt_question = \"How are decision trees used in real-world applications?\"\n",
    "response = llm_chain.invoke({\"dt_question\": dt_question})\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4755325a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Decision trees are widely used in various real-world applications due to their simplicity, interpretability, and effectiveness. Here are some common applications:\\n\\n1. **Healthcare**: Decision trees can help in diagnosing diseases by analyzing patient symptoms and medical history. For example, they can be used to predict whether a patient has a certain condition based on various health indicators.\\n\\n2. **Finance**: In credit scoring, decision trees can assess the risk of lending to an individual by evaluating factors such as credit history, income, and debt levels. They help in making decisions about loan approvals.\\n\\n3. **Marketing**: Businesses use decision trees to segment customers based on purchasing behavior, demographics, and preferences. This helps in targeting marketing campaigns more effectively.\\n\\n4. **Fraud Detection**: Financial institutions employ decision trees to identify potentially fraudulent transactions by analyzing patterns and anomalies in transaction data.\\n\\n5. **Manufacturing**: Decision trees can optimize production processes by analyzing factors that affect product quality and yield, helping to identify the best conditions for manufacturing.\\n\\n6. **Customer Support**: Automated customer service systems use decision trees to guide users through troubleshooting processes based on their responses to specific questions.\\n\\n7. **Risk Management**: Organizations use decision trees to evaluate risks associated with various projects or investments, helping them make informed decisions.\\n\\n8. **Sports Analytics**: Decision trees can analyze player performance and game strategies, assisting coaches and teams in making tactical decisions.\\n\\nOverall, decision trees are versatile tools that can be applied in numerous fields to facilitate decision-making based on data-driven insights.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 310, 'prompt_tokens': 151, 'total_tokens': 461, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CePuZIedt0ds9PMBkSBBnu4ZSev4G', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--54023ce8-15f1-4558-9bca-8d3d5a9909bb-0' usage_metadata={'input_tokens': 151, 'output_tokens': 310, 'total_tokens': 461, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84341729",
   "metadata": {},
   "source": [
    "### Few shot prompt template\n",
    "> The *ChatPromptTemplate* class can handle few examples. If you need to provide more examples then a few shot prompt template is better. You can set up your examples as a pandas dataframe and convert to a dictionary using *pd.to_dict(orient='records)* \n",
    "\n",
    "> Need to provide 2 things\n",
    "* A list of examples\n",
    "* a prompt template that will show how the prompt will be structues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed3b1da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentiment: 5'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate,FewShotPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "# Define the examples\n",
    "df = pd.read_csv('Reviews.csv')\n",
    "\n",
    "examples = df.to_dict(orient='records')\n",
    "\n",
    "example_template = PromptTemplate.from_template(\"Review: {review},Sentiment: {rating}\\n\")\n",
    "\n",
    "prompt_template = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_template,\n",
    "    suffix = \"Review:{input}\",\n",
    "    input_variables = [\"input\"]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI( model=\"gpt-4o-mini\",\n",
    "                    temperature = 0,\n",
    "                    openai_api_key=key)\n",
    "\n",
    "llm_chain = (prompt_template) | (llm)\n",
    "\n",
    "response = llm_chain.invoke({\"input\": \"This movie is the greatest ever\"})\n",
    "\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce0ae8a",
   "metadata": {},
   "source": [
    "### Sequential chains\n",
    "* Some things can only be done sequentially.\n",
    "* Consider a chatbot that plans an itenary\n",
    "    * Recieves destination\n",
    "    * compiles a list of sites\n",
    "    * Chooses top 3 sites and creates an itenary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cd198a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Absolutely! Here are some activities you can enjoy while visiting the must-see attractions in Paris:\\n\\n### Activities Around the Eiffel Tower:\\n1. **Picnic at Champ de Mars**: Grab some fresh baguettes, cheese, and wine from a local market and enjoy a picnic on the lawns of Champ de Mars with a stunning view of the Eiffel Tower.\\n2. **Seine River Cruise**: Take a scenic boat cruise along the Seine River, especially at sunset, to see the Eiffel Tower and other landmarks illuminated at night.\\n3. **Dinner at a Nearby Restaurant**: Enjoy a meal at one of the many restaurants with views of the Eiffel Tower, such as Le Café de l'Homme or Les Ombres.\\n\\n### Activities at the Louvre Museum:\\n1. **Guided Tour**: Consider joining a guided tour to learn more about the history and significance of the artworks, including the Mona Lisa and the Winged Victory of Samothrace.\\n2. **Explore the Tuileries Garden**: After your visit to the Louvre, take a leisurely stroll through the beautiful Tuileries Garden, which is just outside the museum.\\n3. **Attend a Special Exhibition**: Check the Louvre's schedule for any temporary exhibitions that might be taking place during your visit.\\n\\n### Activities Near Notre-Dame Cathedral:\\n1. **Visit Sainte-Chapelle**: Just a short walk from Notre-Dame, this stunning chapel is famous for its breathtaking stained glass windows. It's a must-see for anyone interested in Gothic architecture.\\n2. **Explore Île de la Cité**: Wander around the charming streets of Île de la Cité, where you can find quaint shops, cafes, and the beautiful Place Dauphine.\\n3. **Attend a Concert or Service**: Check if there are any concerts or services happening at Notre-Dame or nearby churches, as they often host beautiful choral performances.\\n\\n### Additional Activities in Paris:\\n- **Montmartre Exploration**: Visit the artistic neighborhood of Montmartre, where you can see the Sacré-Cœur Basilica and explore the charming streets that inspired famous artists.\\n- **Shopping in Le Marais**: Spend some time in the trendy Le Marais district, known for its boutiques, vintage shops, and vibrant atmosphere.\\n- **Culinary Experience**: Take a cooking class or a food tour to learn about French cuisine and taste local delicacies, such as macarons, pastries, and cheeses.\\n\\n### Evening Activities:\\n- **Moulin Rouge Show**: Experience a classic Parisian cabaret show at the Moulin Rouge for a night of entertainment and glamour.\\n- **Night Walk Along the Seine**: Enjoy a romantic evening stroll along the Seine River, taking in the illuminated bridges and landmarks.\\n\\nWith these activities, you'll be able to immerse yourself in the beauty and culture of Paris while enjoying its iconic attractions!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 574, 'prompt_tokens': 262, 'total_tokens': 836, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CeRZt7aH7Wum7N61NUBCWrPgdivBU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--2ccf4472-e3b4-47c5-bee3-271c1e0ae200-0' usage_metadata={'input_tokens': 262, 'output_tokens': 574, 'total_tokens': 836, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "#create destination prompt template\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "destination_prompt = PromptTemplate(input_variables=[\"destination\"],\n",
    "                                    template = \"I am planning a trip to {destination}. Give me a brief overview of the place and suggest 3 must-visit attractions.\")\n",
    "\n",
    "attractions_prompt = PromptTemplate(input_variables=[\"attractions\"],\n",
    "                                   template = \"Based on the following attractions: {attractions}, suggest some activities to do.\")\n",
    "\n",
    "llm = ChatOpenAI( model=\"gpt-4o-mini\",\n",
    "                    temperature = 0,\n",
    "                    openai_api_key=key)\n",
    "\n",
    "seq_chain ={'attractions': destination_prompt | llm | StrOutputParser()} | attractions_prompt | llm\n",
    "response = seq_chain.invoke({\"destination\": \"Paris\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f610fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "skill_gap_template = PromptTemplate(input_variables=[\"current_skills\"],\n",
    "                                    template=\"\"\"Given the skills required for a good data scientist \n",
    "                                    and the current skills {current_skills}, identify the skill gaps. \\\n",
    "                                    \"Keep your response brief and to the point\"\"\"\n",
    "                                    )\n",
    "\n",
    "project_recco_template = PromptTemplate(input_variables=[\"skill_gaps\"],\n",
    "                                    template=\"\"\"Based on the following skill gaps: {skill_gaps}, \n",
    "                                    suggest 2 project ideas that can help in acquiring these skills. \n",
    "                                    \"Provide a brief description for each project idea.\"\"\"\n",
    "                                    )\n",
    "llm = ChatOpenAI( model=\"gpt-4o-mini\",\n",
    "                    temperature = 0,\n",
    "                    openai_api_key=key)\n",
    "\n",
    "seq_chain = {'skill_gaps': skill_gap_template | llm | StrOutputParser()} | project_recco_template | llm\n",
    "response = seq_chain.invoke({\"current_skills\": \"Python, SQL, Basic Statistics\"})\n",
    "\n",
    "with open(\"project_ideas.txt\",\"w\") as f:\n",
    "    f.write(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
